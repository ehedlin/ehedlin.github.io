<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Eric Hedlin</title>
  <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

  <link rel="shortcut icon" href="./assets/img/favicon.ico"> 

  <link rel="stylesheet" href="./assets/css/main.css">
  <link rel="canonical" href="/">
</head>


  <body>

    <header class="site-header"> 

  <div class="wrapper">

    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
          <a class="page-link scholar" href="https://scholar.google.ca/citations?hl=en&user=x6t__GoAAAAJ">
            <span class="icon"></span> Google Scholar
          </a>
          <a class="page-link wikipedia" href="https://en.wikipedia.org/wiki/Eric_Hedlin">
            <span class="icon"></span> Wikipedia
          </a>
          <a class="page-link email" href="mailto:%69%61%6D%65%72%69%63%68%65%64%6C%69%6E@%67%6D%61%69%6C%2E%63%6F%6D">
            <span class="icon"></span> Contact
          </a>
        </div>
    </nav>

  </div>

</header>



<div class="page-content">
  <div class="wrapper">
    <div class="post">
    <header class="post-header">
      <h1 class="post-title"><strong>Eric Hedlin</strong></h1>
      <h5 class="post-description">University of British Columbia, Vancouver</h5>
    </header>

    <article class="post-content <strong>Eric Hedlin</strong> clearfix">
    
    <div class="profile col one right">
        <img class="one" src="./assets/img/2023_K2_SwimmingCanadaAthletePhoto.png" width="256" height=auto>
    </div>
    <p>
      I am a fourth-year PhD student at the 
      <a href="https://vision.cs.ubc.ca/">University of British Columbia</a>, 
      working on optimization-based methods under the supervision of 
      <a href="https://www.cs.ubc.ca/~kmyi/">Prof. Kwang Moo Yi</a>.
    </p>
    <p>
        My main research interests involve using optimization-based approaches 
        to discover emergent phenomena from large pre-trained models.
    </p>
    <p>
        I recently completed a three-month internship with the Qualcomm Perception team in San Diego, 
        where I worked under <a href="https://s-mahajan.github.io/">Shweta Mahajan</a>.
    </p>
    <p>
        Outside of academia, I was on the Canadain national team for 12 years, representing Canada
        in international swimming competitions. I won multiple medals, 
        including a silver and bronze at the World Aquatic Championships in open water swimming.
    </p>


<h2>Publications</h2>
<h3>2024</h3>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
    <tr>
      <td width="35%" valign="middle">
              <img src="./assets/paper_images/hypernetwork_fields.gif" alt="eval" style="vertical-align:middle; width: 100%; margin:0px 10px; border-radius:0%" /> 
      </td>
      <td valign="top" width="85%">
        <p>
            <!-- <b>HyperNet Fields: Efficiently Training Hypernetworks without Ground Truth by Learning Weight Trajectories</b> -->
            <a href="https://arxiv.org/abs/2412.17040"><b>HyperNet Fields: Efficiently Training Hypernetworks without Ground Truth by Learning Weight Trajectories</b></a>
            <br />
            <!-- <b>Eric Hedlin</b>, Gopal Sharma, Shweta Mahajan, Xingzhe He, Hossam Isack, Abhishek Kar, -->
            <!-- Helge Rhodin, Andrea Tagliasacchi, Kwang Moo Yi. -->
            <b>Eric Hedlin</b>, Munawar Hayat, Fatih Porikli, Kwang Moo Yi, Shweta Mahajan
            <br />
            December 2024
            <details>
              <summary>Abstract  </summary>            
                <p class="message">To efficiently adapt large models or to train generative models of neural representations, Hypernetworks have drawn interest. While hypernetworks work well, training them is cumbersome, and often requires ground truth optimized weights for each sample. However, obtaining each of these weights is a training problem of its own-one needs to train, e.g., adaptation weights or even an entire neural field for hypernetworks to regress to. In this work, we propose a method to train hypernetworks, without the need for any per-sample ground truth. Our key idea is to learn a Hypernetwork `Field` and estimate the entire trajectory of network weight training instead of simply its converged state. In other words, we introduce an additional input to the Hypernetwork, the convergence state, which then makes it act as a neural field that models the entire convergence pathway of a task network. A critical benefit in doing so is that the gradient of the estimated weights at any convergence state must then match the gradients of the original task -- this constraint alone is sufficient to train the Hypernetwork Field. We demonstrate the effectiveness of our method through the task of personalized image generation and 3D shape reconstruction from images and point clouds, demonstrating competitive results without any per-sample ground truth.</p> </details>
        </p>  
      </td>
    </tr>
  </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
    <tr>
      <td width="35%" valign="middle">
              <img src="./assets/paper_images/tesla-bots.gif" alt="eval" style="vertical-align:middle; width: 100%; margin:0px 10px; border-radius:0%" /> 
      </td>
      <td valign="top" width="85%">
        <p>
            <!-- <b>Unsupervised Keypoints from Pretrained Diffusion Models</b> -->
            <a href="https://ubc-vision.github.io/StableKeypoints/"><b>Unsupervised Keypoints from Pretrained Diffusion Models</b></a>
            <br />
            <b>Eric Hedlin</b>, Gopal Sharma, Shweta Mahajan, Xingzhe He, Hossam Isack, Abhishek Kar,
            Helge Rhodin, Andrea Tagliasacchi, Kwang Moo Yi.
            <br />
            CVPR 2024 <b>Highlight</b>
            <details>
              <summary>Abstract  </summary>            
                <p class="message">Unsupervised learning of keypoints and landmarks has seen significant progress with the help of modern neural network architectures, but performance is yet to match the supervised counterpart, making their practicability questionable. We leverage the emergent knowledge within text-to-image diffusion models, towards more robust unsupervised keypoints. Our core idea is to find text embeddings that would cause the generative model to consistently attend to compact regions in images (i.e. keypoints). To do so, we simply optimize the text embedding such that the cross-attention maps within the denoising network are localized as Gaussians with small standard deviations. We validate our performance on multiple dataset: the CelebA, CUB-200-2011, Tai-Chi-HD, DeepFashion, and Human3.6m datasets. We achieve significantly improved accuracy, sometimes even outperforming supervised ones, particularly for data that is non-aligned and less curated.</p> </details>
        </p>  
      </td>
    </tr>
  </tr>
</table>

<h3>2023</h3>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
    <tr>
      <td width="35%" valign="middle">
              <img src="./assets/paper_images/correspondence.png" alt="eval" style="vertical-align:middle; width: 100%; margin:0px 10px; border-radius:0%" /> 
      </td>
      <td valign="top" width="85%">
        <p>
          <a href="https://ubc-vision.github.io/LDM_correspondences/"><b>Unsupervised Semantic Correspondence Using Stable Diffusion</b></a>
          <br />
          <b>Eric Hedlin</b>, Gopal Sharma, Shweta Mahajan, Hossam Isack, Abhishek Kar, Andrea Tagliasacchi, Kwang Moo Yi.

          <br />
          NeurIPS 2023
          <details>
            <summary>Abstract  </summary>            
            <p class="message">Text-to-image diffusion models are now capable of generating images that are often indistinguishable from real images. To generate such images, these models must understand the semantics of the objects they are asked to generate. In this work we show that, without any training, one can leverage this semantic knowledge within diffusion models to find semantic correspondences -- locations in multiple images that have the same semantic meaning. Specifically, given an image, we optimize the prompt embeddings of these models for maximum attention on the regions of interest. These optimized embeddings capture semantic information about the location, which can then be transferred to another image. By doing so we obtain results on par with the strongly supervised state of the art on the PF-Willow dataset and significantly outperform (20.9% relative for the SPair-71k dataset) any existing weakly or unsupervised method on PF-Willow, CUB-200 and SPair-71k datasets.</p> </details>
        </p>  
      </td>
    </tr>
  </tr>

  <!-- CNDHF -->
  <tr>
    <tr>
      <td width="35%" valign="middle">
              <img src="./assets/paper_images/CN_DHF.png" alt="eval" style="vertical-align:middle; width: 100%; margin:0px 10px; border-radius:0%" /> 
      </td>
      <td valign="top" width="85%">
            <p>
                <a href="https://arxiv.org/abs/2304.13141"><b>CN-DHF: Compact Neural Double Height-Field Representations of 3D Shapes</b></a>
                <br />
                <b>Eric Hedlin<sup>*</sup></b>, Jinfan Yang<sup>*</sup>, Nicholas Vining, Kwang Moo Yi, Alla Sheffer.

                <br />
                April 2023
      <details>
                  <summary>Abstract  </summary>            
                    <p class="message">We introduce CN-DHF (Compact Neural Double-Height-Field), a novel hybrid neural implicit 3D shape representation that is dramatically more compact than the current state of the art. Our representation leverages Double-Height-Field (DHF) geometries, defined as closed shapes bounded by a pair of oppositely oriented height-fields that share a common axis, and leverages the following key observations: DHFs can be compactly encoded as 2D neural implicits that capture the maximal and minimal heights along the DHF axis; and typical closed 3D shapes are well represented as intersections of a very small number (three or fewer) of DHFs. We represent input geometries as CNDHFs by first computing the set of DHFs whose intersection well approximates each input shape, and then encoding these DHFs via neural fields. Our approach delivers high-quality reconstructions, and reduces the reconstruction error by a factor of 2:5 on average compared to the state-of-the-art, given the same parameter count or storage capacity. Compared to the best-performing alternative, our method produced higher accuracy models on 94% of the 400 input shape and parameter count combinations tested.</p> </details>
            </p>  
      </td>
    </tr>
    </tr>
  </tr>

</table>





<h3>2022</h3>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
     <td width="35%" valign="middle">
      <img src="./assets/paper_images/regressor_refinement.png" alt="eval" style="vertical-align:middle; width: 100%; margin:0px 10px; border-radius:0%" /> 
     </td>
    <td valign="top" width="85%">
      <p>
        <a href="https://arxiv.org/abs/2205.00076"><b>A Simple Method to Boost Human Pose Estimation Accuracy by Correcting the Joint Regressor for the Human3.6m Dataset</b></a>
        <br /><b>Eric Hedlin</b>, Helge Rhodin, Kwang Moo Yi<br />
        May 2022
        <details>
          <summary>Abstract  </summary>            
            <p class="message">Many human pose estimation methods estimate Skinned Multi-Person Linear (SMPL) models and regress the human joints from these SMPL estimates. In this work, we show that the most widely used SMPL-to-joint linear layer (joint regressor) is inaccurate, which may mislead pose evaluation results. To achieve a more accurate joint regressor, we propose a method to create pseudo-ground-truth SMPL poses, which can then be used to train an improved regressor. Specifically, we optimize SMPL estimates coming from a state-of-the-art method so that its projection matches the silhouettes of humans in the scene, as well as the ground-truth 2D joint locations. While the quality of this pseudo-ground-truth is challenging to assess due to the lack of actual ground-truth SMPL, with the Human 3.6m dataset, we qualitatively show that our joint locations are more accurate and that our regressor leads to improved pose estimations results on the test set without any need for retraining. We release our code and joint regressor at <a href="https://github.com/ubc-vision/joint-regressor-refinement">this https URL</a></p> </details>
      </p>  
    </td>
   </tr>
   
</table>

  </article>

  

  
    <div class="social">
  <span class="contacticon center">
    <a href="mailto:%69%61%6D%65%72%69%63%68%65%64%6C%69%6E@%67%6D%61%69%6C%2E%63%6F%6D"><i class="fas fa-envelope"></i></a>
    <a href="https://scholar.google.ca/citations?hl=en&user=x6t__GoAAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>
    
    
    
    
    
  </span>

  <div class="col three caption">
    
  </div>
</div>

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    &copy; Copyright 2020 Gopal Sharma.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>.

    
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="./assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="./assets/js/katex.js"></script>



<!-- Load Anchor JS -->
<script src="//cdnjs.cloudflare.com/ajax/libs/anchor-js/3.2.2/anchor.min.js"></script>
<script>
  anchors.options.visible = 'always';
  anchors.add('article h2, article h3, article h4, article h5, article h6');
</script>


<!-- Include custom icon fonts -->
<link rel="stylesheet" href="./assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="./assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-XXXXXXXXX', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
